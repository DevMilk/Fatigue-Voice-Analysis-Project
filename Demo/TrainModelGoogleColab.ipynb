{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Araproje.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uiYPdRABEwNs",
        "VdVzFOpGEz83",
        "V2TmIE6BEyrn",
        "c99c5CdlFaRV",
        "w9NCJnulGCTP",
        "brwa4D70mcxN"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J_s0EaR88Wo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1ff4d130-bb52-4530-d145-c5a776906fb2"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!nvcc --version\n",
        "!nvidia-smi\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.test.gpu_device_name())\n",
        "import seaborn as sns\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, UpSampling2D, InputLayer, Reshape, GlobalAveragePooling2D, Dropout, GlobalMaxPool2D\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.densenet import DenseNet201\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "from keras import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "import pprint  # for pretty printing our device stats\n",
        "from google.colab import files\n",
        "print(\"Tensorflow version \" + tf.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "\n",
            "Tensorflow version 1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiYPdRABEwNs",
        "colab_type": "text"
      },
      "source": [
        "# Connecting to Drive and Setting Up the Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xZneJB7uOSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c6bdc4fa-1095-46b6-b757-ce471a31100f"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llOPq3wUuiLL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d844593-372e-48f6-ced4-5f122b779c11"
      },
      "source": [
        "#cd \"drive/My Drive/MatlabSpectrogram\"\n",
        "%cd \"gdrive/My Drive\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdVzFOpGEz83",
        "colab_type": "text"
      },
      "source": [
        "# Function for creating models, getting data from drive by generators and training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4nkzuOFKJWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras.regularizers import l1\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import load_model, save_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "#DataGenerators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255, width_shift_range=0.26, fill_mode=\"constant\")\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "#Reshape parameter\n",
        "WINDOW = 224\n",
        " \n",
        "#Create train and test data\n",
        "def create_datagens(path, onlyTest=False, testAll=False,batch_size=64, printPath=True):\n",
        "  \n",
        "    stype = path.split(\"_\",1)[1]\n",
        "    save_path = \"Models/FVA_\" +stype +\".h5\"\n",
        "\n",
        "    global checkpoint\n",
        "    checkpoint = ModelCheckpoint(\n",
        "      save_path,\n",
        "      monitor='val_accuracy',\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      mode='max',\n",
        "      period=1)\n",
        "\n",
        "    train = []\n",
        "    if (not onlyTest):\n",
        "        #Flow train data from rive\n",
        "        train = train_datagen.flow_from_directory(\n",
        "            directory=path + \"/Train/\",\n",
        "            target_size=(WINDOW, WINDOW),\n",
        "            batch_size=batch_size,\n",
        "            class_mode=\"categorical\")\n",
        "        #Flow test data from rive\n",
        "    newPath = path\n",
        "    if (testAll):\n",
        "        newPath = newPath.replace(\"123_8910\", \"all\")\n",
        "        newPath = newPath.replace(\"12_910\", \"all\")\n",
        "        newPath = newPath.replace(\"1_10\", \"all\")\n",
        "    test = test_datagen.flow_from_directory(\n",
        "        directory=newPath + '/Test/',\n",
        "        target_size=(WINDOW, WINDOW),\n",
        "        batch_size=1,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "    #return datagens\n",
        "    return train, test,save_path\n",
        "\n",
        "\n",
        "#Create transfer learning Model\n",
        "def create_model(ModelFunction,\n",
        "                 optimizer,\n",
        "                 learning_rate,\n",
        "                 act,\n",
        "                 loss,\n",
        "                 early=False,\n",
        "                 tpu=False,\n",
        "                 extra_layers=[]):\n",
        "\n",
        "    pretrained_model = ModelFunction(\n",
        "        weights=\"imagenet\",\n",
        "        include_top=False,\n",
        "        input_shape=(WINDOW, WINDOW, 3),\n",
        "        classes=2,\n",
        "        pooling=\"max\"\n",
        "    )  #ignore last 10000 neuron which represents predictions ! SHAPE YAPILMADAN INPUT_SHAPE= (852,572,3) YAPILABİLİR\n",
        "    x = pretrained_model.output\n",
        "    #2 class = 2 outputs\n",
        "    for layer in extra_layers:\n",
        "      x = layer(x)\n",
        "    output = Dense(2, activation=act)(x)\n",
        "\n",
        "    for layer in pretrained_model.layers:\n",
        "        layer.trainable = True\n",
        "\n",
        "    model = Sequential()\n",
        "    model = Model(inputs=pretrained_model.inputs, outputs=output)\n",
        "    for layer in model.layers[:(-6-len(extra_layers))]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizer(lr=learning_rate), loss=loss, metrics=[\"accuracy\"])\n",
        "\n",
        "    #print(model.summary())\n",
        "    return model\n",
        "\n",
        "\n",
        "#create model with tpu or not\n",
        "def create_new_model(ModelFunction,\n",
        "                     optimizer,\n",
        "                     learning_rate,\n",
        "                     act,\n",
        "                     loss,\n",
        "                     early=False,\n",
        "                     tpu=False,\n",
        "                     loadModel=\" \",\n",
        "                     extra_layers=[]):\n",
        "    if (loadModel == \" \"):\n",
        "        if (tpu):\n",
        "            tpu_strategy = tf.distribute.experimental.TPUStrategy(tpur)\n",
        "            with tpu_strategy.scope(\n",
        "            ):  # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "                model = create_model(ModelFunction, optimizer, learning_rate,\n",
        "                                     act, loss, early, tp,extra_layers)\n",
        "        else:\n",
        "            model = create_model(ModelFunction, optimizer, learning_rate, act,\n",
        "                                 loss, early, tpu,extra_layers)\n",
        "    else:\n",
        "        model = load_model(loadModel)\n",
        "    return model\n",
        "\n",
        "\n",
        "#train model\n",
        "def train_model(model, generators, epochs=300, save=False,callbacks=[]):\n",
        "    callb = []\n",
        "    #CALLBACK FUNCTIONS\n",
        "    if (save):\n",
        "        callb = callbacks.copy()\n",
        "        callb.append(checkpoint) \n",
        "\n",
        "    #TRAIN\n",
        "    hist = model.fit_generator(\n",
        "        generator=generators[0],\n",
        "        steps_per_epoch=generators[0].n // generators[0].batch_size,\n",
        "        validation_data=generators[1],\n",
        "        validation_steps=generators[1].n // generators[1].batch_size,\n",
        "        epochs=epochs,\n",
        "        use_multiprocessing=True,\n",
        "        workers=0,\n",
        "        verbose=1,\n",
        "        callbacks=callb)\n",
        "\n",
        "    #RETURN HISTORY\n",
        "    return hist\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2TmIE6BEyrn",
        "colab_type": "text"
      },
      "source": [
        "# Setting Up Parameters For Fine-Tuning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MX5IObMFZfAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "import pandas as pd\n",
        "                                                                        \n",
        "\"\"\"function ConnectButton(){\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#connect\").click() \n",
        "}\n",
        "setInterval(ConnectButton,60000);\n",
        "\n",
        "CTRL+SHIFT+I YAZIP KONSOL BUNU YAZ.\"\"\"\n",
        "\n",
        "#OPTIMIZATION PARAMETERS\n",
        "LRchange = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.15,\n",
        "    patience=150,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    min_delta=0.001,\n",
        "    cooldown=0,\n",
        "    min_lr=0.00000001)\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=150)\n",
        "\n",
        "models=[VGG16,ResNet50,VGG16,VGG19,NASNetMobile,MobileNet,MobileNetV2,DenseNet201]#VGG16,ResNet50,VGG16,VGG19,NASNetMobile,MobileNet,MobileNetV2,DenseNet201\n",
        "opts = [optimizers.Adam,optimizers.RMSprop,optimizers.Nadam,optimizers.SGD,optimizers.Adamax,optimizers.Adadelta]#optimizers.Adam,optimizers.RMSprop,optimizers.Nadam,optimizers.SGD,optimizers.Adamax,optimizers.Adadelta\n",
        "acts = [\"softmax\",\"sigmoid\"]#\"softmax\",\"sigmoid\"\n",
        "losses = [\"categorical_crossentropy\",\"binary_crossentropy\"]#\"categorical_crossentropy\",\"binary_crossentropy\"\n",
        "learning_rates=[0.000008,0.08,0.02,0.0002,0.00008,0.00002,0.000002,0.0000008,0.0000002]\n",
        "epochs=[450] #EARLY STOPPING YAPILIRSA GEREK KALMAZ\n",
        "callbacks = []\n",
        "trained_models=[]\n",
        "extra_layers_array=[[Dropout(0.2)]]\n",
        "batch_size= 64\n",
        "save = False\n",
        "#SPEKTOGRAM BİLGİLERİ(ERB,BARK,LOG,MEL), OPTİMİZER, MODELLER,ACTIVATION(SOFTMAX,SIGMOID),LOSS(BINARY_CROSS,HINGE LOSS, CATEGORY?) FINE TUNINGDE BULUNACAK.\n",
        "#4*5*4*7*2*3*15*8\n",
        "generators = np.empty(shape=(16,5,2),dtype=object) # 16 klasör, 5 fold, (1 train-test)\n",
        "histories = np.empty(shape=(16,5),dtype=object) # 16 klasör, 5 fold, (1 train-test)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c99c5CdlFaRV",
        "colab_type": "text"
      },
      "source": [
        "# Getting File Names and Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bweN3SadGnqP",
        "colab_type": "text"
      },
      "source": [
        "Getting Letter Voice Spectrogram Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8Bgy9Ofot-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2c109523-2b19-4e85-e3f9-9db65c7dfbeb"
      },
      "source": [
        "files_for_tuning = []\n",
        "for folder in os.listdir(\"MatlabSpectrogram-harf\" ):\n",
        "  if(\"1_10\" in folder   ):\n",
        "    files_for_tuning.append(\"MatlabSpectrogram-harf/\"+folder)\n",
        "    print(\"unsorted folds order: \",os.listdir(\"MatlabSpectrogram-harf/\"+folder))\n",
        "files_for_tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unsorted folds order:  ['f4', 'f3', 'f2', 'f1', 'f5']\n",
            "unsorted folds order:  ['f1', 'f4', 'f2', 'f5', 'f3']\n",
            "unsorted folds order:  ['f5', 'f3', 'f1', 'f2', 'f4']\n",
            "unsorted folds order:  ['f1', 'f3', 'f5', 'f4', 'f2']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MatlabSpectrogram-harf/Spect_LOG_1_10_harf',\n",
              " 'MatlabSpectrogram-harf/Spect_MEL_1_10_harf',\n",
              " 'MatlabSpectrogram-harf/Spect_BARK_1_10_harf',\n",
              " 'MatlabSpectrogram-harf/Spect_ERB_1_10_harf']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKGw9LybGsTB",
        "colab_type": "text"
      },
      "source": [
        "Getting Word Voice Spectrogram Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vfcidSsnkkA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e886f636-06b5-4161-dc46-43934694dac2"
      },
      "source": [
        "files_for_tuning = []\n",
        "for folder in os.listdir(\"MatlabSpectrogram-kelime\" ):\n",
        "  if(\"all\" in folder ):\n",
        "    files_for_tuning.append(\"MatlabSpectrogram-kelime/\"+folder)\n",
        "    print(\"unsorted folds order: \",os.listdir(\"MatlabSpectrogram-kelime/\"+folder))\n",
        "files_for_tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unsorted folds order:  ['f5', 'f1', 'f3', 'f4', 'f2']\n",
            "unsorted folds order:  ['f2', 'f3', 'f5', 'f1', 'f4']\n",
            "unsorted folds order:  ['f1', 'f2', 'f4', 'f3', 'f5']\n",
            "unsorted folds order:  ['f1', 'f2', 'f3', 'f4', 'f5']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MatlabSpectrogram-kelime/Spect_BARK_all_kelime',\n",
              " 'MatlabSpectrogram-kelime/Spect_ERB_all_kelime',\n",
              " 'MatlabSpectrogram-kelime/Spect_LOG_all_kelime',\n",
              " 'MatlabSpectrogram-kelime/Spect_MEL_all_kelime']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3z0oBj2bSXF",
        "colab_type": "text"
      },
      "source": [
        "Training by checking all combinations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghJYOO6cZ_T7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f74fe607-fa38-4827-c4a9-bd3530a11507"
      },
      "source": [
        " \n",
        "for i in range(0, len(files_for_tuning)):\n",
        "    folds = os.listdir(files_for_tuning[i])\n",
        "    folds.sort()\n",
        "    print(\"sorted: \" ,folds)\n",
        "    for model in models:\n",
        "        for optimizer in opts:\n",
        "            for act in acts:\n",
        "                for loss in losses:\n",
        "                    for lr in learning_rates:\n",
        "                        for ep in epochs:\n",
        "                          for extra_layers in extra_layers_array:\n",
        "                              foldscore = 0\n",
        "                              foldtrscore = 0\n",
        "                              save_path=\"\"\n",
        "                              for j in range(0,len(folds)):  #\n",
        "                                  modeltmp = create_new_model(\n",
        "                                      model, optimizer, lr, act, loss,\n",
        "                                      tpu=False,extra_layers=extra_layers)  #,loadModel=\"Models/FVA_MEL.h5\"\n",
        "                                  print(modeltmp.summary())    \n",
        "                                  generators[i][j][0], generators[i][j][1],save_path =create_datagens(\n",
        "                                          files_for_tuning[i] + \"/\" + folds[j],\n",
        "                                          testAll=False,batch_size=batch_size)\n",
        "                                  \n",
        "                                  print(\"Model will be saved to path: \"+ save_path)\n",
        "\n",
        "                                  history = train_model(\n",
        "                                      modeltmp, generators[i][j], ep, save=save,\n",
        "                                      callbacks= callbacks)\n",
        "\n",
        "                                  histories[i][j] = history\n",
        "\n",
        "                                  trained_models.append(modeltmp)\n",
        "                                  test = max(history.history[\"val_accuracy\"])\n",
        "                                  tr = history.history[\"accuracy\"][\n",
        "                                      history.history[\"val_accuracy\"].index(\n",
        "                                          test)]\n",
        "\n",
        "                                  foldscore += test\n",
        "                                  foldtrscore += tr\n",
        "                                  plt.plot(history.history[\"accuracy\"])\n",
        "                                  plt.plot(history.history[\"val_accuracy\"])\n",
        "                                  plt.show()\n",
        "                                  print(\n",
        "                                      \"file= {}, {} train score: {} test score: {} ,lr = {},\\noptimizer = {}, act = {},extralayers= {},batchsize={}\".\n",
        "                                      format(files_for_tuning[i], folds[j], tr, test,\n",
        "                                            lr, optimizer,act,extra_layers,batch_size))\n",
        "\n",
        "\n",
        "                            #print(\"General train performance: {}, test performance: {}\".format(foldtrscore/5,foldscore/5))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sorted:  ['f1', 'f2', 'f3', 'f4', 'f5']\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 14,715,714\n",
            "Trainable params: 7,080,450\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "None\n",
            "Found 1016 images belonging to 2 classes.\n",
            "Found 254 images belonging to 2 classes.\n",
            "Model will be saved to path: Models/FVA_BARK_all_kelime/f1.h5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/450\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6a43675341aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                                  history = train_model(\n\u001b[1;32m     28\u001b[0m                                      \u001b[0mmodeltmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                      callbacks= callbacks)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                  \u001b[0mhistories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-8164c489a86a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, generators, epochs, save, callbacks)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         callbacks=callb)\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m#RETURN HISTORY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36miter_sequence_infinite\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \"\"\"\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9NCJnulGCTP",
        "colab_type": "text"
      },
      "source": [
        "# Combined Dataset Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxYnp5CrGJtx",
        "colab_type": "text"
      },
      "source": [
        "Created a keras Sequence object to combine 2 datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm4nf1F7ETdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import Sequence\n",
        "class TwoImageGenerator(Sequence):\n",
        "\n",
        "  def __init__(self, generator1, generator2):\n",
        "      self.generator1 = generator1\n",
        "      self.generator2 = generator2\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "      i2= i\n",
        "      generator = self.generator1\n",
        "      if(len(self.generator1)<=i2):\n",
        "        i2 = i-len(self.generator1)\n",
        "        generator = self.generator2\n",
        "      \n",
        "      X1i = generator[i2]\n",
        "\n",
        "      imgFirst = X1i[0]\n",
        "      imgi = np.zeros((len(imgFirst), 224, 224, 3), dtype=np.float32)\n",
        "      targets =np.zeros((len(imgFirst), 2), dtype=np.float32)\n",
        "      for n in range(0, len(imgFirst)):\n",
        "          imgi[n] = imgFirst[n]\n",
        "          targets[n] = X1i[1][n]\n",
        "    \n",
        "      return imgi, targets\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.generator1)+len(self.generator2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uk6syV5VGRR9",
        "colab_type": "text"
      },
      "source": [
        "Getting files for combine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQO9HrcW8sij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4b706eb2-9ec0-4a21-d86f-349a2445ce73"
      },
      "source": [
        "files_for_tuning = []\n",
        "for folder in os.listdir(\"MatlabSpectrogram-kelime\" ):\n",
        "  if(\"123_8910\" in folder ):\n",
        "    files_for_tuning.append(\"MatlabSpectrogram-kelime/\"+folder)\n",
        "    print(\"unsorted folds order: \",os.listdir(\"MatlabSpectrogram-kelime/\"+folder))\n",
        "\n",
        "for folder in os.listdir(\"MatlabSpectrogram-harf\" ):\n",
        "  if(\"123_8910\" in folder    ):\n",
        "    files_for_tuning.append(\"MatlabSpectrogram-harf/\"+folder)\n",
        "    print(\"unsorted folds order: \",os.listdir(\"MatlabSpectrogram-harf/\"+folder))\n",
        "files_for_tuning.sort()\n",
        "files_for_tuning"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unsorted folds order:  ['f1', 'f2', 'f3', 'f4', 'f5']\n",
            "unsorted folds order:  ['f1', 'f2', 'f5', 'f3', 'f4']\n",
            "unsorted folds order:  ['f3', 'f4', 'f1', 'f2', 'f5']\n",
            "unsorted folds order:  ['f1', 'f4', 'f2', 'f5', 'f3']\n",
            "unsorted folds order:  ['f2', 'f1', 'f5', 'f3', 'f4']\n",
            "unsorted folds order:  ['f5', 'f1', 'f3', 'f2', 'f4']\n",
            "unsorted folds order:  ['f4', 'f1', 'f2', 'f3', 'f5']\n",
            "unsorted folds order:  ['f3', 'f2', 'f5', 'f4', 'f1']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MatlabSpectrogram-harf/Spect_BARK_123_8910_harf',\n",
              " 'MatlabSpectrogram-harf/Spect_ERB_123_8910_harf',\n",
              " 'MatlabSpectrogram-harf/Spect_LOG_123_8910_harf',\n",
              " 'MatlabSpectrogram-harf/Spect_MEL_123_8910_harf',\n",
              " 'MatlabSpectrogram-kelime/Spect_BARK_123_8910_kelime',\n",
              " 'MatlabSpectrogram-kelime/Spect_ERB_123_8910_kelime',\n",
              " 'MatlabSpectrogram-kelime/Spect_LOG_123_8910_kelime',\n",
              " 'MatlabSpectrogram-kelime/Spect_MEL_123_8910_kelime']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th-c3t8JG6Lh",
        "colab_type": "text"
      },
      "source": [
        "Run training for all combinations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoGhIaeN8scC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6062df5e-e61a-4387-cd9f-ce7ec2d258a8"
      },
      "source": [
        " \n",
        "for i in range(0, len(files_for_tuning)):\n",
        "    folds = os.listdir(files_for_tuning[i])\n",
        "    folds.sort()\n",
        "    print(\"sorted: \" ,folds)\n",
        "    for model in models:\n",
        "        for optimizer in opts:\n",
        "            for act in acts:\n",
        "                for loss in losses:\n",
        "                    for lr in learning_rates:\n",
        "                        for ep in epochs:\n",
        "                          for extra_layers in extra_layers_array:\n",
        "                              foldscore = 0\n",
        "                              foldtrscore = 0\n",
        "                              save_path=\"\"\n",
        "                              for j in range(0,len(folds)):   \n",
        "                                  modeltmp = create_new_model(\n",
        "                                      model, optimizer, lr, act, loss,\n",
        "                                      tpu=False,extra_layers=extra_layers) \n",
        "                                  traingen1, testgen1,save_path =create_datagens(\n",
        "                                          files_for_tuning[i] + \"/\" + folds[j],\n",
        "                                          testAll=False,batch_size=batch_size)\n",
        "                                  traingen2, testgen2,save_path =create_datagens(\n",
        "                                          files_for_tuning[i+4] + \"/\" + folds[j],\n",
        "                                          testAll=False,batch_size=batch_size)\n",
        "                                  traingen,testgen =  TwoImageGenerator(traingen1,traingen2), TwoImageGenerator(testgen1,testgen2)\n",
        "                                  checkpoint = ModelCheckpoint(\n",
        "                                      save_path+\"deney\"+\".h5\",\n",
        "                                      monitor='val_accuracy',\n",
        "                                      verbose=1,\n",
        "                                      save_best_only=True,\n",
        "                                      mode='max',\n",
        "                                      period=1)\n",
        "                                   \n",
        "                                  history = modeltmp.fit_generator(\n",
        "                                                generator=traingen,\n",
        "                                                steps_per_epoch=len(traingen), \n",
        "                                                validation_data=testgen,\n",
        "                                                validation_steps=len(testgen),\n",
        "                                                epochs=ep,\n",
        "                                                use_multiprocessing=True,\n",
        "                                                workers=0,\n",
        "                                                verbose=1,\n",
        "                                                callbacks=[])\n",
        "\n",
        "                                  test = max(history.history[\"val_accuracy\"])\n",
        "                                  tr = history.history[\"accuracy\"][\n",
        "                                      history.history[\"val_accuracy\"].index(\n",
        "                                          test)]\n",
        "\n",
        "                                  foldscore += test\n",
        "                                  foldtrscore += tr\n",
        "                                  plt.plot(history.history[\"accuracy\"])\n",
        "                                  plt.plot(history.history[\"val_accuracy\"])\n",
        "                                  plt.show()\n",
        "                                  print(\n",
        "                                      \"file= {}+{}, fold: {}, train score: {} test score: {} ,lr = {},\\noptimizer = {}, act = {},extralayers= {},batchsize={}\".\n",
        "                                      format(files_for_tuning[i],files_for_tuning[i+4], folds[j], tr, test,\n",
        "                                            lr, optimizer,act,extra_layers,batch_size))\n",
        "\n",
        "\n",
        "                            #print(\"General train performance: {}, test performance: {}\".format(foldtrscore/5,foldscore/5))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sorted:  ['f1', 'f2', 'f3', 'f4', 'f5']\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Found 667 images belonging to 2 classes.\n",
            "Found 167 images belonging to 2 classes.\n",
            "Found 593 images belonging to 2 classes.\n",
            "Found 221 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/450\n",
            "21/21 [==============================] - 579s 28s/step - loss: 0.8434 - accuracy: 0.4976 - val_loss: 0.7035 - val_accuracy: 0.5284\n",
            "Epoch 2/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7767 - accuracy: 0.4905 - val_loss: 0.6974 - val_accuracy: 0.5387\n",
            "Epoch 3/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7469 - accuracy: 0.5206 - val_loss: 0.6810 - val_accuracy: 0.4923\n",
            "Epoch 4/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7508 - accuracy: 0.4905 - val_loss: 0.6983 - val_accuracy: 0.5180\n",
            "Epoch 5/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.7315 - accuracy: 0.5167 - val_loss: 0.6641 - val_accuracy: 0.5052\n",
            "Epoch 6/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7546 - accuracy: 0.4770 - val_loss: 0.6842 - val_accuracy: 0.5412\n",
            "Epoch 7/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7181 - accuracy: 0.5413 - val_loss: 0.7100 - val_accuracy: 0.5284\n",
            "Epoch 8/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.7238 - accuracy: 0.5127 - val_loss: 0.6894 - val_accuracy: 0.5361\n",
            "Epoch 9/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7331 - accuracy: 0.5032 - val_loss: 0.6876 - val_accuracy: 0.5361\n",
            "Epoch 10/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.7292 - accuracy: 0.5071 - val_loss: 0.6921 - val_accuracy: 0.5206\n",
            "Epoch 11/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7248 - accuracy: 0.5238 - val_loss: 0.7205 - val_accuracy: 0.5232\n",
            "Epoch 12/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7283 - accuracy: 0.5087 - val_loss: 0.7576 - val_accuracy: 0.5464\n",
            "Epoch 13/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7063 - accuracy: 0.5349 - val_loss: 0.7772 - val_accuracy: 0.5490\n",
            "Epoch 14/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7009 - accuracy: 0.5230 - val_loss: 0.7399 - val_accuracy: 0.5490\n",
            "Epoch 15/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7095 - accuracy: 0.5190 - val_loss: 0.7543 - val_accuracy: 0.5515\n",
            "Epoch 16/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.7027 - accuracy: 0.5325 - val_loss: 0.7119 - val_accuracy: 0.5464\n",
            "Epoch 17/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6893 - accuracy: 0.5611 - val_loss: 0.7683 - val_accuracy: 0.5438\n",
            "Epoch 18/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6936 - accuracy: 0.5460 - val_loss: 0.7895 - val_accuracy: 0.5438\n",
            "Epoch 19/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6958 - accuracy: 0.5476 - val_loss: 0.7979 - val_accuracy: 0.5644\n",
            "Epoch 20/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6858 - accuracy: 0.5524 - val_loss: 0.7589 - val_accuracy: 0.5696\n",
            "Epoch 21/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6867 - accuracy: 0.5595 - val_loss: 0.7476 - val_accuracy: 0.5567\n",
            "Epoch 22/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6802 - accuracy: 0.5635 - val_loss: 0.7644 - val_accuracy: 0.5773\n",
            "Epoch 23/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6886 - accuracy: 0.5460 - val_loss: 0.7581 - val_accuracy: 0.5722\n",
            "Epoch 24/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6831 - accuracy: 0.5849 - val_loss: 0.7767 - val_accuracy: 0.5722\n",
            "Epoch 25/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6722 - accuracy: 0.5873 - val_loss: 0.7991 - val_accuracy: 0.5696\n",
            "Epoch 26/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6639 - accuracy: 0.5921 - val_loss: 0.7816 - val_accuracy: 0.5825\n",
            "Epoch 27/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6540 - accuracy: 0.6048 - val_loss: 0.7900 - val_accuracy: 0.5747\n",
            "Epoch 28/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6697 - accuracy: 0.5675 - val_loss: 0.7811 - val_accuracy: 0.5799\n",
            "Epoch 29/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6603 - accuracy: 0.5944 - val_loss: 0.7939 - val_accuracy: 0.5876\n",
            "Epoch 30/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6533 - accuracy: 0.6016 - val_loss: 0.8035 - val_accuracy: 0.5851\n",
            "Epoch 31/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6533 - accuracy: 0.6071 - val_loss: 0.7716 - val_accuracy: 0.5851\n",
            "Epoch 32/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6528 - accuracy: 0.6151 - val_loss: 0.7804 - val_accuracy: 0.5799\n",
            "Epoch 33/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6604 - accuracy: 0.6079 - val_loss: 0.8125 - val_accuracy: 0.5876\n",
            "Epoch 34/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6540 - accuracy: 0.5976 - val_loss: 0.7856 - val_accuracy: 0.5902\n",
            "Epoch 35/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6333 - accuracy: 0.6294 - val_loss: 0.7860 - val_accuracy: 0.5851\n",
            "Epoch 36/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6435 - accuracy: 0.5984 - val_loss: 0.8099 - val_accuracy: 0.5902\n",
            "Epoch 37/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6404 - accuracy: 0.6278 - val_loss: 0.8378 - val_accuracy: 0.5876\n",
            "Epoch 38/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6444 - accuracy: 0.6198 - val_loss: 0.7535 - val_accuracy: 0.5954\n",
            "Epoch 39/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6291 - accuracy: 0.6302 - val_loss: 0.7645 - val_accuracy: 0.5928\n",
            "Epoch 40/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6327 - accuracy: 0.6270 - val_loss: 0.7537 - val_accuracy: 0.5876\n",
            "Epoch 41/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6215 - accuracy: 0.6508 - val_loss: 0.7743 - val_accuracy: 0.5825\n",
            "Epoch 42/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6244 - accuracy: 0.6310 - val_loss: 0.8124 - val_accuracy: 0.6057\n",
            "Epoch 43/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6206 - accuracy: 0.6524 - val_loss: 0.7982 - val_accuracy: 0.5954\n",
            "Epoch 44/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6107 - accuracy: 0.6619 - val_loss: 0.7679 - val_accuracy: 0.6005\n",
            "Epoch 45/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6219 - accuracy: 0.6389 - val_loss: 0.8464 - val_accuracy: 0.5979\n",
            "Epoch 46/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6175 - accuracy: 0.6405 - val_loss: 0.7743 - val_accuracy: 0.6005\n",
            "Epoch 47/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6219 - accuracy: 0.6476 - val_loss: 0.7519 - val_accuracy: 0.6031\n",
            "Epoch 48/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6109 - accuracy: 0.6468 - val_loss: 0.7338 - val_accuracy: 0.6057\n",
            "Epoch 49/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6023 - accuracy: 0.6595 - val_loss: 0.7343 - val_accuracy: 0.6134\n",
            "Epoch 50/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6051 - accuracy: 0.6532 - val_loss: 0.8004 - val_accuracy: 0.6108\n",
            "Epoch 51/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5999 - accuracy: 0.6524 - val_loss: 0.7405 - val_accuracy: 0.5979\n",
            "Epoch 52/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.6066 - accuracy: 0.6524 - val_loss: 0.8000 - val_accuracy: 0.6160\n",
            "Epoch 53/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5897 - accuracy: 0.6794 - val_loss: 0.6546 - val_accuracy: 0.6134\n",
            "Epoch 54/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5807 - accuracy: 0.6865 - val_loss: 0.7722 - val_accuracy: 0.6237\n",
            "Epoch 55/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5866 - accuracy: 0.6706 - val_loss: 0.7337 - val_accuracy: 0.6031\n",
            "Epoch 56/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5906 - accuracy: 0.6754 - val_loss: 0.8090 - val_accuracy: 0.6005\n",
            "Epoch 57/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.6091 - accuracy: 0.6421 - val_loss: 0.8307 - val_accuracy: 0.5928\n",
            "Epoch 58/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5821 - accuracy: 0.7024 - val_loss: 0.6848 - val_accuracy: 0.6289\n",
            "Epoch 59/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.5662 - accuracy: 0.6944 - val_loss: 0.6801 - val_accuracy: 0.6289\n",
            "Epoch 60/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5576 - accuracy: 0.7024 - val_loss: 0.6760 - val_accuracy: 0.6108\n",
            "Epoch 61/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5653 - accuracy: 0.6976 - val_loss: 0.7362 - val_accuracy: 0.6108\n",
            "Epoch 62/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5952 - accuracy: 0.6730 - val_loss: 0.7920 - val_accuracy: 0.6031\n",
            "Epoch 63/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5953 - accuracy: 0.6746 - val_loss: 0.7174 - val_accuracy: 0.6598\n",
            "Epoch 64/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5743 - accuracy: 0.6937 - val_loss: 0.5232 - val_accuracy: 0.6392\n",
            "Epoch 65/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5547 - accuracy: 0.7040 - val_loss: 0.7266 - val_accuracy: 0.6392\n",
            "Epoch 66/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5497 - accuracy: 0.7135 - val_loss: 0.6953 - val_accuracy: 0.6263\n",
            "Epoch 67/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5629 - accuracy: 0.6976 - val_loss: 0.7733 - val_accuracy: 0.6134\n",
            "Epoch 68/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5608 - accuracy: 0.6984 - val_loss: 0.7312 - val_accuracy: 0.6031\n",
            "Epoch 69/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5659 - accuracy: 0.6865 - val_loss: 0.8096 - val_accuracy: 0.6134\n",
            "Epoch 70/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5583 - accuracy: 0.7008 - val_loss: 0.7033 - val_accuracy: 0.6263\n",
            "Epoch 71/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.5367 - accuracy: 0.7270 - val_loss: 0.7115 - val_accuracy: 0.6211\n",
            "Epoch 72/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5289 - accuracy: 0.7294 - val_loss: 0.6984 - val_accuracy: 0.6314\n",
            "Epoch 73/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5402 - accuracy: 0.7143 - val_loss: 0.7120 - val_accuracy: 0.6186\n",
            "Epoch 74/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5496 - accuracy: 0.7119 - val_loss: 0.7028 - val_accuracy: 0.6237\n",
            "Epoch 75/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5412 - accuracy: 0.7175 - val_loss: 0.7412 - val_accuracy: 0.6314\n",
            "Epoch 76/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5374 - accuracy: 0.7111 - val_loss: 0.6597 - val_accuracy: 0.6289\n",
            "Epoch 77/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5224 - accuracy: 0.7325 - val_loss: 0.6778 - val_accuracy: 0.6340\n",
            "Epoch 78/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5210 - accuracy: 0.7357 - val_loss: 0.6599 - val_accuracy: 0.6289\n",
            "Epoch 79/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5260 - accuracy: 0.7071 - val_loss: 0.7314 - val_accuracy: 0.6134\n",
            "Epoch 80/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5347 - accuracy: 0.7190 - val_loss: 0.7110 - val_accuracy: 0.6237\n",
            "Epoch 81/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5133 - accuracy: 0.7460 - val_loss: 0.6414 - val_accuracy: 0.6546\n",
            "Epoch 82/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5060 - accuracy: 0.7556 - val_loss: 0.6250 - val_accuracy: 0.6727\n",
            "Epoch 83/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4948 - accuracy: 0.7627 - val_loss: 0.6100 - val_accuracy: 0.6443\n",
            "Epoch 84/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.5020 - accuracy: 0.7476 - val_loss: 0.7107 - val_accuracy: 0.6263\n",
            "Epoch 85/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.5149 - accuracy: 0.7437 - val_loss: 0.6888 - val_accuracy: 0.6237\n",
            "Epoch 86/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.5185 - accuracy: 0.7278 - val_loss: 0.7025 - val_accuracy: 0.6314\n",
            "Epoch 87/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.5080 - accuracy: 0.7437 - val_loss: 0.6954 - val_accuracy: 0.6314\n",
            "Epoch 88/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4973 - accuracy: 0.7659 - val_loss: 0.6509 - val_accuracy: 0.6289\n",
            "Epoch 89/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.5011 - accuracy: 0.7444 - val_loss: 0.6393 - val_accuracy: 0.6366\n",
            "Epoch 90/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4961 - accuracy: 0.7595 - val_loss: 0.6248 - val_accuracy: 0.6314\n",
            "Epoch 91/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.4896 - accuracy: 0.7619 - val_loss: 0.6091 - val_accuracy: 0.6340\n",
            "Epoch 92/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4819 - accuracy: 0.7579 - val_loss: 0.7090 - val_accuracy: 0.6366\n",
            "Epoch 93/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4827 - accuracy: 0.7603 - val_loss: 0.6445 - val_accuracy: 0.6263\n",
            "Epoch 94/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4771 - accuracy: 0.7619 - val_loss: 0.6245 - val_accuracy: 0.6418\n",
            "Epoch 95/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4660 - accuracy: 0.7667 - val_loss: 0.6206 - val_accuracy: 0.6289\n",
            "Epoch 96/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4717 - accuracy: 0.7706 - val_loss: 0.6352 - val_accuracy: 0.6263\n",
            "Epoch 97/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.4829 - accuracy: 0.7540 - val_loss: 0.6876 - val_accuracy: 0.6340\n",
            "Epoch 98/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4841 - accuracy: 0.7595 - val_loss: 0.6811 - val_accuracy: 0.6598\n",
            "Epoch 99/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4615 - accuracy: 0.7833 - val_loss: 0.6426 - val_accuracy: 0.6572\n",
            "Epoch 100/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4552 - accuracy: 0.7897 - val_loss: 0.6113 - val_accuracy: 0.6598\n",
            "Epoch 101/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4424 - accuracy: 0.7944 - val_loss: 0.6145 - val_accuracy: 0.6289\n",
            "Epoch 102/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4529 - accuracy: 0.7825 - val_loss: 0.6288 - val_accuracy: 0.6443\n",
            "Epoch 103/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4796 - accuracy: 0.7540 - val_loss: 0.6933 - val_accuracy: 0.6366\n",
            "Epoch 104/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4576 - accuracy: 0.7857 - val_loss: 0.6114 - val_accuracy: 0.6624\n",
            "Epoch 105/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4377 - accuracy: 0.8016 - val_loss: 0.5632 - val_accuracy: 0.6778\n",
            "Epoch 106/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4391 - accuracy: 0.7992 - val_loss: 0.5817 - val_accuracy: 0.6546\n",
            "Epoch 107/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4599 - accuracy: 0.7714 - val_loss: 0.6632 - val_accuracy: 0.6392\n",
            "Epoch 108/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4649 - accuracy: 0.7651 - val_loss: 0.6269 - val_accuracy: 0.6366\n",
            "Epoch 109/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4469 - accuracy: 0.7897 - val_loss: 0.6099 - val_accuracy: 0.6392\n",
            "Epoch 110/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4358 - accuracy: 0.7968 - val_loss: 0.5641 - val_accuracy: 0.6469\n",
            "Epoch 111/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4311 - accuracy: 0.8095 - val_loss: 0.5372 - val_accuracy: 0.6495\n",
            "Epoch 112/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4435 - accuracy: 0.7817 - val_loss: 0.5931 - val_accuracy: 0.6443\n",
            "Epoch 113/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4476 - accuracy: 0.7849 - val_loss: 0.6017 - val_accuracy: 0.6392\n",
            "Epoch 114/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4313 - accuracy: 0.8000 - val_loss: 0.5432 - val_accuracy: 0.6443\n",
            "Epoch 115/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4317 - accuracy: 0.8008 - val_loss: 0.5122 - val_accuracy: 0.6727\n",
            "Epoch 116/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.4115 - accuracy: 0.8167 - val_loss: 0.5533 - val_accuracy: 0.6546\n",
            "Epoch 117/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4125 - accuracy: 0.8175 - val_loss: 0.5291 - val_accuracy: 0.6624\n",
            "Epoch 118/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4129 - accuracy: 0.8183 - val_loss: 0.5440 - val_accuracy: 0.6572\n",
            "Epoch 119/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4256 - accuracy: 0.8159 - val_loss: 0.5855 - val_accuracy: 0.6495\n",
            "Epoch 120/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4225 - accuracy: 0.8071 - val_loss: 0.6156 - val_accuracy: 0.6521\n",
            "Epoch 121/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4180 - accuracy: 0.8063 - val_loss: 0.5135 - val_accuracy: 0.6624\n",
            "Epoch 122/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4137 - accuracy: 0.8056 - val_loss: 0.5998 - val_accuracy: 0.6469\n",
            "Epoch 123/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4004 - accuracy: 0.8238 - val_loss: 0.5514 - val_accuracy: 0.6443\n",
            "Epoch 124/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3979 - accuracy: 0.8254 - val_loss: 0.5217 - val_accuracy: 0.6624\n",
            "Epoch 125/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3979 - accuracy: 0.8238 - val_loss: 0.5919 - val_accuracy: 0.6624\n",
            "Epoch 126/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3934 - accuracy: 0.8286 - val_loss: 0.5537 - val_accuracy: 0.6649\n",
            "Epoch 127/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3872 - accuracy: 0.8325 - val_loss: 0.5425 - val_accuracy: 0.6624\n",
            "Epoch 128/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3988 - accuracy: 0.8183 - val_loss: 0.5390 - val_accuracy: 0.6521\n",
            "Epoch 129/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.4139 - accuracy: 0.7952 - val_loss: 0.6304 - val_accuracy: 0.6469\n",
            "Epoch 130/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4031 - accuracy: 0.8127 - val_loss: 0.5305 - val_accuracy: 0.7062\n",
            "Epoch 131/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3746 - accuracy: 0.8341 - val_loss: 0.5254 - val_accuracy: 0.7088\n",
            "Epoch 132/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3714 - accuracy: 0.8460 - val_loss: 0.4697 - val_accuracy: 0.6856\n",
            "Epoch 133/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3881 - accuracy: 0.8214 - val_loss: 0.4196 - val_accuracy: 0.6443\n",
            "Epoch 134/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4370 - accuracy: 0.7675 - val_loss: 0.3078 - val_accuracy: 0.5644\n",
            "Epoch 135/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4931 - accuracy: 0.7579 - val_loss: 0.3973 - val_accuracy: 0.6933\n",
            "Epoch 136/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.3881 - accuracy: 0.8460 - val_loss: 0.5053 - val_accuracy: 0.6804\n",
            "Epoch 137/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3768 - accuracy: 0.8325 - val_loss: 0.5589 - val_accuracy: 0.6649\n",
            "Epoch 138/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3825 - accuracy: 0.8357 - val_loss: 0.5598 - val_accuracy: 0.6907\n",
            "Epoch 139/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3537 - accuracy: 0.8540 - val_loss: 0.4878 - val_accuracy: 0.7113\n",
            "Epoch 140/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3352 - accuracy: 0.8754 - val_loss: 0.4873 - val_accuracy: 0.7088\n",
            "Epoch 141/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3579 - accuracy: 0.8516 - val_loss: 0.4643 - val_accuracy: 0.6933\n",
            "Epoch 142/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.3748 - accuracy: 0.8198 - val_loss: 0.4504 - val_accuracy: 0.6495\n",
            "Epoch 143/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4126 - accuracy: 0.7960 - val_loss: 0.3230 - val_accuracy: 0.5928\n",
            "Epoch 144/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4252 - accuracy: 0.7968 - val_loss: 0.4866 - val_accuracy: 0.7088\n",
            "Epoch 145/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3468 - accuracy: 0.8603 - val_loss: 0.4569 - val_accuracy: 0.7088\n",
            "Epoch 146/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3405 - accuracy: 0.8532 - val_loss: 0.4369 - val_accuracy: 0.7268\n",
            "Epoch 147/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3347 - accuracy: 0.8563 - val_loss: 0.4278 - val_accuracy: 0.7088\n",
            "Epoch 148/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3436 - accuracy: 0.8579 - val_loss: 0.4111 - val_accuracy: 0.6933\n",
            "Epoch 149/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3650 - accuracy: 0.8325 - val_loss: 0.3214 - val_accuracy: 0.6572\n",
            "Epoch 150/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3945 - accuracy: 0.8111 - val_loss: 0.3476 - val_accuracy: 0.6572\n",
            "Epoch 151/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3672 - accuracy: 0.8373 - val_loss: 0.3927 - val_accuracy: 0.6778\n",
            "Epoch 152/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3396 - accuracy: 0.8556 - val_loss: 0.3393 - val_accuracy: 0.6959\n",
            "Epoch 153/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3349 - accuracy: 0.8571 - val_loss: 0.4039 - val_accuracy: 0.7088\n",
            "Epoch 154/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3306 - accuracy: 0.8516 - val_loss: 0.3695 - val_accuracy: 0.6701\n",
            "Epoch 155/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3366 - accuracy: 0.8548 - val_loss: 0.3147 - val_accuracy: 0.6572\n",
            "Epoch 156/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3486 - accuracy: 0.8452 - val_loss: 0.3581 - val_accuracy: 0.6598\n",
            "Epoch 157/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3551 - accuracy: 0.8421 - val_loss: 0.3152 - val_accuracy: 0.6727\n",
            "Epoch 158/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3422 - accuracy: 0.8548 - val_loss: 0.3426 - val_accuracy: 0.6933\n",
            "Epoch 159/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3161 - accuracy: 0.8810 - val_loss: 0.4526 - val_accuracy: 0.7216\n",
            "Epoch 160/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3192 - accuracy: 0.8675 - val_loss: 0.3811 - val_accuracy: 0.7165\n",
            "Epoch 161/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3117 - accuracy: 0.8778 - val_loss: 0.4388 - val_accuracy: 0.6856\n",
            "Epoch 162/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3186 - accuracy: 0.8651 - val_loss: 0.4199 - val_accuracy: 0.6753\n",
            "Epoch 163/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3723 - accuracy: 0.8222 - val_loss: 0.5895 - val_accuracy: 0.6263\n",
            "Epoch 164/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4215 - accuracy: 0.7937 - val_loss: 0.6115 - val_accuracy: 0.6907\n",
            "Epoch 165/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3223 - accuracy: 0.8540 - val_loss: 0.3639 - val_accuracy: 0.7088\n",
            "Epoch 166/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3117 - accuracy: 0.8698 - val_loss: 0.3060 - val_accuracy: 0.6804\n",
            "Epoch 167/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3164 - accuracy: 0.8730 - val_loss: 0.3402 - val_accuracy: 0.7036\n",
            "Epoch 168/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3097 - accuracy: 0.8690 - val_loss: 0.3497 - val_accuracy: 0.7113\n",
            "Epoch 169/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3025 - accuracy: 0.8754 - val_loss: 0.3402 - val_accuracy: 0.7165\n",
            "Epoch 170/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2971 - accuracy: 0.8841 - val_loss: 0.3685 - val_accuracy: 0.7113\n",
            "Epoch 171/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2869 - accuracy: 0.8944 - val_loss: 0.3701 - val_accuracy: 0.7165\n",
            "Epoch 172/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2868 - accuracy: 0.8857 - val_loss: 0.4052 - val_accuracy: 0.7165\n",
            "Epoch 173/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2956 - accuracy: 0.8786 - val_loss: 0.3693 - val_accuracy: 0.7165\n",
            "Epoch 174/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2863 - accuracy: 0.8833 - val_loss: 0.4845 - val_accuracy: 0.7216\n",
            "Epoch 175/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2771 - accuracy: 0.9040 - val_loss: 0.4272 - val_accuracy: 0.7242\n",
            "Epoch 176/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2847 - accuracy: 0.8944 - val_loss: 0.4951 - val_accuracy: 0.7216\n",
            "Epoch 177/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2842 - accuracy: 0.8770 - val_loss: 0.4816 - val_accuracy: 0.7036\n",
            "Epoch 178/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2798 - accuracy: 0.8944 - val_loss: 0.4600 - val_accuracy: 0.7088\n",
            "Epoch 179/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2788 - accuracy: 0.8929 - val_loss: 0.4348 - val_accuracy: 0.7113\n",
            "Epoch 180/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2706 - accuracy: 0.8921 - val_loss: 0.3758 - val_accuracy: 0.6933\n",
            "Epoch 181/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3090 - accuracy: 0.8603 - val_loss: 0.4545 - val_accuracy: 0.6701\n",
            "Epoch 182/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4268 - accuracy: 0.7754 - val_loss: 0.7172 - val_accuracy: 0.5876\n",
            "Epoch 183/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4184 - accuracy: 0.8056 - val_loss: 0.2955 - val_accuracy: 0.6263\n",
            "Epoch 184/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.4350 - accuracy: 0.7881 - val_loss: 0.4029 - val_accuracy: 0.6675\n",
            "Epoch 185/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3571 - accuracy: 0.8310 - val_loss: 0.3092 - val_accuracy: 0.7036\n",
            "Epoch 186/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3056 - accuracy: 0.8675 - val_loss: 0.5883 - val_accuracy: 0.6727\n",
            "Epoch 187/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2808 - accuracy: 0.8849 - val_loss: 0.4487 - val_accuracy: 0.7216\n",
            "Epoch 188/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2689 - accuracy: 0.9000 - val_loss: 0.4043 - val_accuracy: 0.7242\n",
            "Epoch 189/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2679 - accuracy: 0.8968 - val_loss: 0.4281 - val_accuracy: 0.7320\n",
            "Epoch 190/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2648 - accuracy: 0.8944 - val_loss: 0.4177 - val_accuracy: 0.7268\n",
            "Epoch 191/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2780 - accuracy: 0.8944 - val_loss: 0.4420 - val_accuracy: 0.7191\n",
            "Epoch 192/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2749 - accuracy: 0.9032 - val_loss: 0.4378 - val_accuracy: 0.7036\n",
            "Epoch 193/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2882 - accuracy: 0.8778 - val_loss: 0.4560 - val_accuracy: 0.7010\n",
            "Epoch 194/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2866 - accuracy: 0.8841 - val_loss: 0.4628 - val_accuracy: 0.6778\n",
            "Epoch 195/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3002 - accuracy: 0.8762 - val_loss: 0.4492 - val_accuracy: 0.6727\n",
            "Epoch 196/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2792 - accuracy: 0.8881 - val_loss: 0.4448 - val_accuracy: 0.7165\n",
            "Epoch 197/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2590 - accuracy: 0.8960 - val_loss: 0.3592 - val_accuracy: 0.7191\n",
            "Epoch 198/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2548 - accuracy: 0.9032 - val_loss: 0.3158 - val_accuracy: 0.7242\n",
            "Epoch 199/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2652 - accuracy: 0.8857 - val_loss: 0.3155 - val_accuracy: 0.7113\n",
            "Epoch 200/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2749 - accuracy: 0.8857 - val_loss: 0.2649 - val_accuracy: 0.6933\n",
            "Epoch 201/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2570 - accuracy: 0.8984 - val_loss: 0.3907 - val_accuracy: 0.7216\n",
            "Epoch 202/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2587 - accuracy: 0.8929 - val_loss: 0.3089 - val_accuracy: 0.7113\n",
            "Epoch 203/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2643 - accuracy: 0.8889 - val_loss: 0.2733 - val_accuracy: 0.7036\n",
            "Epoch 204/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2452 - accuracy: 0.9040 - val_loss: 0.3771 - val_accuracy: 0.7294\n",
            "Epoch 205/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2367 - accuracy: 0.9143 - val_loss: 0.3380 - val_accuracy: 0.7423\n",
            "Epoch 206/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2371 - accuracy: 0.9151 - val_loss: 0.3318 - val_accuracy: 0.7320\n",
            "Epoch 207/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2363 - accuracy: 0.9135 - val_loss: 0.3714 - val_accuracy: 0.7320\n",
            "Epoch 208/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2404 - accuracy: 0.9048 - val_loss: 0.3099 - val_accuracy: 0.7268\n",
            "Epoch 209/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2435 - accuracy: 0.8992 - val_loss: 0.4079 - val_accuracy: 0.7268\n",
            "Epoch 210/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2492 - accuracy: 0.8968 - val_loss: 0.2873 - val_accuracy: 0.6985\n",
            "Epoch 211/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2603 - accuracy: 0.8929 - val_loss: 0.3025 - val_accuracy: 0.7062\n",
            "Epoch 212/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2616 - accuracy: 0.8825 - val_loss: 0.2823 - val_accuracy: 0.7062\n",
            "Epoch 213/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2652 - accuracy: 0.8849 - val_loss: 0.2416 - val_accuracy: 0.6959\n",
            "Epoch 214/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2494 - accuracy: 0.9040 - val_loss: 0.3115 - val_accuracy: 0.7371\n",
            "Epoch 215/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2380 - accuracy: 0.9087 - val_loss: 0.3745 - val_accuracy: 0.7294\n",
            "Epoch 216/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2290 - accuracy: 0.9159 - val_loss: 0.3219 - val_accuracy: 0.7397\n",
            "Epoch 217/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2179 - accuracy: 0.9222 - val_loss: 0.3621 - val_accuracy: 0.7268\n",
            "Epoch 218/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2343 - accuracy: 0.9119 - val_loss: 0.3858 - val_accuracy: 0.7062\n",
            "Epoch 219/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3234 - accuracy: 0.8516 - val_loss: 0.4945 - val_accuracy: 0.6237\n",
            "Epoch 220/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3578 - accuracy: 0.8452 - val_loss: 0.4646 - val_accuracy: 0.6959\n",
            "Epoch 221/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2547 - accuracy: 0.8865 - val_loss: 0.4071 - val_accuracy: 0.7294\n",
            "Epoch 222/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2449 - accuracy: 0.9024 - val_loss: 0.2262 - val_accuracy: 0.7191\n",
            "Epoch 223/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2191 - accuracy: 0.9302 - val_loss: 0.2883 - val_accuracy: 0.7474\n",
            "Epoch 224/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2190 - accuracy: 0.9183 - val_loss: 0.3093 - val_accuracy: 0.7320\n",
            "Epoch 225/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2173 - accuracy: 0.9262 - val_loss: 0.3545 - val_accuracy: 0.7242\n",
            "Epoch 226/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2183 - accuracy: 0.9111 - val_loss: 0.3144 - val_accuracy: 0.7165\n",
            "Epoch 227/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2750 - accuracy: 0.8817 - val_loss: 0.4202 - val_accuracy: 0.6804\n",
            "Epoch 228/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3165 - accuracy: 0.8532 - val_loss: 0.6107 - val_accuracy: 0.6675\n",
            "Epoch 229/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2395 - accuracy: 0.8992 - val_loss: 0.2580 - val_accuracy: 0.7216\n",
            "Epoch 230/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2185 - accuracy: 0.9167 - val_loss: 0.2661 - val_accuracy: 0.7294\n",
            "Epoch 231/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.2203 - accuracy: 0.9135 - val_loss: 0.2696 - val_accuracy: 0.7448\n",
            "Epoch 232/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2078 - accuracy: 0.9183 - val_loss: 0.3241 - val_accuracy: 0.7474\n",
            "Epoch 233/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.2044 - accuracy: 0.9325 - val_loss: 0.3462 - val_accuracy: 0.7371\n",
            "Epoch 234/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.2066 - accuracy: 0.9341 - val_loss: 0.3712 - val_accuracy: 0.7371\n",
            "Epoch 235/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.2048 - accuracy: 0.9262 - val_loss: 0.3324 - val_accuracy: 0.7191\n",
            "Epoch 236/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.2316 - accuracy: 0.9016 - val_loss: 0.3638 - val_accuracy: 0.7191\n",
            "Epoch 237/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.2715 - accuracy: 0.8810 - val_loss: 0.5331 - val_accuracy: 0.6495\n",
            "Epoch 238/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.2688 - accuracy: 0.8825 - val_loss: 0.3875 - val_accuracy: 0.7062\n",
            "Epoch 239/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.2160 - accuracy: 0.9198 - val_loss: 0.3257 - val_accuracy: 0.7448\n",
            "Epoch 240/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.1947 - accuracy: 0.9389 - val_loss: 0.3377 - val_accuracy: 0.7397\n",
            "Epoch 241/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.1989 - accuracy: 0.9325 - val_loss: 0.3840 - val_accuracy: 0.7448\n",
            "Epoch 242/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1976 - accuracy: 0.9317 - val_loss: 0.3880 - val_accuracy: 0.7423\n",
            "Epoch 243/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2029 - accuracy: 0.9254 - val_loss: 0.3530 - val_accuracy: 0.7268\n",
            "Epoch 244/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2274 - accuracy: 0.9000 - val_loss: 0.2417 - val_accuracy: 0.7294\n",
            "Epoch 245/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2273 - accuracy: 0.8968 - val_loss: 0.2081 - val_accuracy: 0.7320\n",
            "Epoch 246/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2210 - accuracy: 0.9111 - val_loss: 0.1880 - val_accuracy: 0.7216\n",
            "Epoch 247/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2156 - accuracy: 0.9222 - val_loss: 0.2418 - val_accuracy: 0.7268\n",
            "Epoch 248/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2143 - accuracy: 0.9127 - val_loss: 0.1948 - val_accuracy: 0.7320\n",
            "Epoch 249/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1900 - accuracy: 0.9365 - val_loss: 0.2397 - val_accuracy: 0.7423\n",
            "Epoch 250/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1792 - accuracy: 0.9468 - val_loss: 0.3005 - val_accuracy: 0.7397\n",
            "Epoch 251/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1821 - accuracy: 0.9357 - val_loss: 0.3033 - val_accuracy: 0.7371\n",
            "Epoch 252/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1810 - accuracy: 0.9397 - val_loss: 0.2669 - val_accuracy: 0.7448\n",
            "Epoch 253/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1797 - accuracy: 0.9452 - val_loss: 0.2865 - val_accuracy: 0.7320\n",
            "Epoch 254/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2053 - accuracy: 0.9143 - val_loss: 0.3272 - val_accuracy: 0.7294\n",
            "Epoch 255/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2867 - accuracy: 0.8611 - val_loss: 0.5435 - val_accuracy: 0.6263\n",
            "Epoch 256/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.3020 - accuracy: 0.8651 - val_loss: 0.4242 - val_accuracy: 0.7062\n",
            "Epoch 257/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1889 - accuracy: 0.9254 - val_loss: 0.3477 - val_accuracy: 0.7320\n",
            "Epoch 258/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1998 - accuracy: 0.9262 - val_loss: 0.2159 - val_accuracy: 0.7448\n",
            "Epoch 259/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1910 - accuracy: 0.9333 - val_loss: 0.2380 - val_accuracy: 0.7448\n",
            "Epoch 260/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1815 - accuracy: 0.9341 - val_loss: 0.3242 - val_accuracy: 0.7448\n",
            "Epoch 261/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1883 - accuracy: 0.9270 - val_loss: 0.2741 - val_accuracy: 0.7474\n",
            "Epoch 262/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1890 - accuracy: 0.9254 - val_loss: 0.2437 - val_accuracy: 0.7397\n",
            "Epoch 263/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1659 - accuracy: 0.9444 - val_loss: 0.2123 - val_accuracy: 0.7474\n",
            "Epoch 264/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1689 - accuracy: 0.9397 - val_loss: 0.2858 - val_accuracy: 0.7397\n",
            "Epoch 265/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1675 - accuracy: 0.9444 - val_loss: 0.2430 - val_accuracy: 0.7294\n",
            "Epoch 266/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1755 - accuracy: 0.9405 - val_loss: 0.2851 - val_accuracy: 0.7371\n",
            "Epoch 267/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1852 - accuracy: 0.9214 - val_loss: 0.3213 - val_accuracy: 0.7294\n",
            "Epoch 268/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2146 - accuracy: 0.9048 - val_loss: 0.4179 - val_accuracy: 0.6881\n",
            "Epoch 269/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2404 - accuracy: 0.9016 - val_loss: 0.4261 - val_accuracy: 0.6753\n",
            "Epoch 270/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2386 - accuracy: 0.9000 - val_loss: 0.3645 - val_accuracy: 0.7268\n",
            "Epoch 271/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2069 - accuracy: 0.9135 - val_loss: 0.3513 - val_accuracy: 0.7191\n",
            "Epoch 272/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1729 - accuracy: 0.9397 - val_loss: 0.2688 - val_accuracy: 0.7345\n",
            "Epoch 273/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1698 - accuracy: 0.9437 - val_loss: 0.2543 - val_accuracy: 0.7397\n",
            "Epoch 274/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1610 - accuracy: 0.9492 - val_loss: 0.2744 - val_accuracy: 0.7448\n",
            "Epoch 275/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1540 - accuracy: 0.9492 - val_loss: 0.2496 - val_accuracy: 0.7423\n",
            "Epoch 276/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1613 - accuracy: 0.9444 - val_loss: 0.3493 - val_accuracy: 0.7371\n",
            "Epoch 277/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1573 - accuracy: 0.9476 - val_loss: 0.2745 - val_accuracy: 0.7423\n",
            "Epoch 278/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1685 - accuracy: 0.9429 - val_loss: 0.3026 - val_accuracy: 0.7500\n",
            "Epoch 279/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1863 - accuracy: 0.9310 - val_loss: 0.3138 - val_accuracy: 0.7191\n",
            "Epoch 280/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1984 - accuracy: 0.9183 - val_loss: 0.3417 - val_accuracy: 0.7113\n",
            "Epoch 281/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1841 - accuracy: 0.9349 - val_loss: 0.3893 - val_accuracy: 0.7320\n",
            "Epoch 282/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1681 - accuracy: 0.9405 - val_loss: 0.3429 - val_accuracy: 0.7345\n",
            "Epoch 283/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1499 - accuracy: 0.9500 - val_loss: 0.3623 - val_accuracy: 0.7371\n",
            "Epoch 284/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1495 - accuracy: 0.9611 - val_loss: 0.2634 - val_accuracy: 0.7448\n",
            "Epoch 285/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1535 - accuracy: 0.9492 - val_loss: 0.2964 - val_accuracy: 0.7474\n",
            "Epoch 286/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1464 - accuracy: 0.9540 - val_loss: 0.2739 - val_accuracy: 0.7500\n",
            "Epoch 287/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1651 - accuracy: 0.9437 - val_loss: 0.2795 - val_accuracy: 0.7397\n",
            "Epoch 288/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1896 - accuracy: 0.9190 - val_loss: 0.2001 - val_accuracy: 0.7294\n",
            "Epoch 289/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1762 - accuracy: 0.9405 - val_loss: 0.2312 - val_accuracy: 0.7320\n",
            "Epoch 290/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2014 - accuracy: 0.9095 - val_loss: 0.2974 - val_accuracy: 0.7397\n",
            "Epoch 291/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2209 - accuracy: 0.8944 - val_loss: 0.1148 - val_accuracy: 0.6649\n",
            "Epoch 292/450\n",
            "21/21 [==============================] - 49s 2s/step - loss: 0.1643 - accuracy: 0.9429 - val_loss: 0.3663 - val_accuracy: 0.7268\n",
            "Epoch 293/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1452 - accuracy: 0.9563 - val_loss: 0.2720 - val_accuracy: 0.7448\n",
            "Epoch 294/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1581 - accuracy: 0.9413 - val_loss: 0.3027 - val_accuracy: 0.7371\n",
            "Epoch 295/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1899 - accuracy: 0.9190 - val_loss: 0.3439 - val_accuracy: 0.7242\n",
            "Epoch 296/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1889 - accuracy: 0.9214 - val_loss: 0.3732 - val_accuracy: 0.7191\n",
            "Epoch 297/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1603 - accuracy: 0.9476 - val_loss: 0.3050 - val_accuracy: 0.7320\n",
            "Epoch 298/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1433 - accuracy: 0.9571 - val_loss: 0.3387 - val_accuracy: 0.7294\n",
            "Epoch 299/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1364 - accuracy: 0.9603 - val_loss: 0.3222 - val_accuracy: 0.7268\n",
            "Epoch 300/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1329 - accuracy: 0.9643 - val_loss: 0.2590 - val_accuracy: 0.7345\n",
            "Epoch 301/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1347 - accuracy: 0.9571 - val_loss: 0.2169 - val_accuracy: 0.7474\n",
            "Epoch 302/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1512 - accuracy: 0.9413 - val_loss: 0.2515 - val_accuracy: 0.7448\n",
            "Epoch 303/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1806 - accuracy: 0.9270 - val_loss: 0.2001 - val_accuracy: 0.7423\n",
            "Epoch 304/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1612 - accuracy: 0.9397 - val_loss: 0.1891 - val_accuracy: 0.7423\n",
            "Epoch 305/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1560 - accuracy: 0.9500 - val_loss: 0.2035 - val_accuracy: 0.7474\n",
            "Epoch 306/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1602 - accuracy: 0.9365 - val_loss: 0.1822 - val_accuracy: 0.7423\n",
            "Epoch 307/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1497 - accuracy: 0.9444 - val_loss: 0.1853 - val_accuracy: 0.7423\n",
            "Epoch 308/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1287 - accuracy: 0.9619 - val_loss: 0.2307 - val_accuracy: 0.7448\n",
            "Epoch 309/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1439 - accuracy: 0.9500 - val_loss: 0.2443 - val_accuracy: 0.7448\n",
            "Epoch 310/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1397 - accuracy: 0.9524 - val_loss: 0.1654 - val_accuracy: 0.7397\n",
            "Epoch 311/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1368 - accuracy: 0.9556 - val_loss: 0.2157 - val_accuracy: 0.7423\n",
            "Epoch 312/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1577 - accuracy: 0.9302 - val_loss: 0.1644 - val_accuracy: 0.7423\n",
            "Epoch 313/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1429 - accuracy: 0.9516 - val_loss: 0.1783 - val_accuracy: 0.7423\n",
            "Epoch 314/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1337 - accuracy: 0.9540 - val_loss: 0.1992 - val_accuracy: 0.7474\n",
            "Epoch 315/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1338 - accuracy: 0.9611 - val_loss: 0.2045 - val_accuracy: 0.7448\n",
            "Epoch 316/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1256 - accuracy: 0.9611 - val_loss: 0.2251 - val_accuracy: 0.7371\n",
            "Epoch 317/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1410 - accuracy: 0.9500 - val_loss: 0.2950 - val_accuracy: 0.7474\n",
            "Epoch 318/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1939 - accuracy: 0.9246 - val_loss: 0.4140 - val_accuracy: 0.7036\n",
            "Epoch 319/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2195 - accuracy: 0.9095 - val_loss: 0.5244 - val_accuracy: 0.6649\n",
            "Epoch 320/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1993 - accuracy: 0.9198 - val_loss: 0.3134 - val_accuracy: 0.7242\n",
            "Epoch 321/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1497 - accuracy: 0.9429 - val_loss: 0.3119 - val_accuracy: 0.7371\n",
            "Epoch 322/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1287 - accuracy: 0.9619 - val_loss: 0.2880 - val_accuracy: 0.7423\n",
            "Epoch 323/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1192 - accuracy: 0.9675 - val_loss: 0.2738 - val_accuracy: 0.7397\n",
            "Epoch 324/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1189 - accuracy: 0.9675 - val_loss: 0.2369 - val_accuracy: 0.7371\n",
            "Epoch 325/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1158 - accuracy: 0.9659 - val_loss: 0.2827 - val_accuracy: 0.7397\n",
            "Epoch 326/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1104 - accuracy: 0.9730 - val_loss: 0.3510 - val_accuracy: 0.7500\n",
            "Epoch 327/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1191 - accuracy: 0.9635 - val_loss: 0.2772 - val_accuracy: 0.7448\n",
            "Epoch 328/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1166 - accuracy: 0.9619 - val_loss: 0.3044 - val_accuracy: 0.7397\n",
            "Epoch 329/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1120 - accuracy: 0.9651 - val_loss: 0.2675 - val_accuracy: 0.7448\n",
            "Epoch 330/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1169 - accuracy: 0.9627 - val_loss: 0.5011 - val_accuracy: 0.7371\n",
            "Epoch 331/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1755 - accuracy: 0.9206 - val_loss: 0.3362 - val_accuracy: 0.7500\n",
            "Epoch 332/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1791 - accuracy: 0.9254 - val_loss: 0.1031 - val_accuracy: 0.7010\n",
            "Epoch 333/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1481 - accuracy: 0.9413 - val_loss: 0.3423 - val_accuracy: 0.7320\n",
            "Epoch 334/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1329 - accuracy: 0.9563 - val_loss: 0.3276 - val_accuracy: 0.7448\n",
            "Epoch 335/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1078 - accuracy: 0.9698 - val_loss: 0.2186 - val_accuracy: 0.7500\n",
            "Epoch 336/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1161 - accuracy: 0.9651 - val_loss: 0.2938 - val_accuracy: 0.7448\n",
            "Epoch 337/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1168 - accuracy: 0.9611 - val_loss: 0.3435 - val_accuracy: 0.7552\n",
            "Epoch 338/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1098 - accuracy: 0.9627 - val_loss: 0.2908 - val_accuracy: 0.7423\n",
            "Epoch 339/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1013 - accuracy: 0.9762 - val_loss: 0.2518 - val_accuracy: 0.7423\n",
            "Epoch 340/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1326 - accuracy: 0.9524 - val_loss: 0.2723 - val_accuracy: 0.7552\n",
            "Epoch 341/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1417 - accuracy: 0.9421 - val_loss: 0.1993 - val_accuracy: 0.7345\n",
            "Epoch 342/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1278 - accuracy: 0.9587 - val_loss: 0.1632 - val_accuracy: 0.7448\n",
            "Epoch 343/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1028 - accuracy: 0.9722 - val_loss: 0.1917 - val_accuracy: 0.7397\n",
            "Epoch 344/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1096 - accuracy: 0.9683 - val_loss: 0.1740 - val_accuracy: 0.7500\n",
            "Epoch 345/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1067 - accuracy: 0.9714 - val_loss: 0.1853 - val_accuracy: 0.7448\n",
            "Epoch 346/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1086 - accuracy: 0.9659 - val_loss: 0.2325 - val_accuracy: 0.7552\n",
            "Epoch 347/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1543 - accuracy: 0.9325 - val_loss: 0.3079 - val_accuracy: 0.7268\n",
            "Epoch 348/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2115 - accuracy: 0.9024 - val_loss: 0.4321 - val_accuracy: 0.6624\n",
            "Epoch 349/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1804 - accuracy: 0.9302 - val_loss: 0.3783 - val_accuracy: 0.7320\n",
            "Epoch 350/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1127 - accuracy: 0.9651 - val_loss: 0.2284 - val_accuracy: 0.7320\n",
            "Epoch 351/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1024 - accuracy: 0.9714 - val_loss: 0.3294 - val_accuracy: 0.7397\n",
            "Epoch 352/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1040 - accuracy: 0.9706 - val_loss: 0.3237 - val_accuracy: 0.7371\n",
            "Epoch 353/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0974 - accuracy: 0.9722 - val_loss: 0.2731 - val_accuracy: 0.7448\n",
            "Epoch 354/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1034 - accuracy: 0.9746 - val_loss: 0.2207 - val_accuracy: 0.7423\n",
            "Epoch 355/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1098 - accuracy: 0.9635 - val_loss: 0.2757 - val_accuracy: 0.7448\n",
            "Epoch 356/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1148 - accuracy: 0.9627 - val_loss: 0.2783 - val_accuracy: 0.7345\n",
            "Epoch 357/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1068 - accuracy: 0.9659 - val_loss: 0.3278 - val_accuracy: 0.7500\n",
            "Epoch 358/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1117 - accuracy: 0.9635 - val_loss: 0.3043 - val_accuracy: 0.7526\n",
            "Epoch 359/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1014 - accuracy: 0.9738 - val_loss: 0.2559 - val_accuracy: 0.7371\n",
            "Epoch 360/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0930 - accuracy: 0.9786 - val_loss: 0.3475 - val_accuracy: 0.7552\n",
            "Epoch 361/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0892 - accuracy: 0.9794 - val_loss: 0.2941 - val_accuracy: 0.7474\n",
            "Epoch 362/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0966 - accuracy: 0.9754 - val_loss: 0.3563 - val_accuracy: 0.7423\n",
            "Epoch 363/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0964 - accuracy: 0.9746 - val_loss: 0.2402 - val_accuracy: 0.7345\n",
            "Epoch 364/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1331 - accuracy: 0.9460 - val_loss: 0.2249 - val_accuracy: 0.7500\n",
            "Epoch 365/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1449 - accuracy: 0.9405 - val_loss: 0.1186 - val_accuracy: 0.7165\n",
            "Epoch 366/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1129 - accuracy: 0.9651 - val_loss: 0.2248 - val_accuracy: 0.7474\n",
            "Epoch 367/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1193 - accuracy: 0.9595 - val_loss: 0.2162 - val_accuracy: 0.7577\n",
            "Epoch 368/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1002 - accuracy: 0.9659 - val_loss: 0.1932 - val_accuracy: 0.7526\n",
            "Epoch 369/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1060 - accuracy: 0.9579 - val_loss: 0.1840 - val_accuracy: 0.7552\n",
            "Epoch 370/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0966 - accuracy: 0.9746 - val_loss: 0.1526 - val_accuracy: 0.7552\n",
            "Epoch 371/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0879 - accuracy: 0.9833 - val_loss: 0.1906 - val_accuracy: 0.7474\n",
            "Epoch 372/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0829 - accuracy: 0.9849 - val_loss: 0.2176 - val_accuracy: 0.7423\n",
            "Epoch 373/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0853 - accuracy: 0.9810 - val_loss: 0.2333 - val_accuracy: 0.7397\n",
            "Epoch 374/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1066 - accuracy: 0.9635 - val_loss: 0.2578 - val_accuracy: 0.7448\n",
            "Epoch 375/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1511 - accuracy: 0.9294 - val_loss: 0.3428 - val_accuracy: 0.7216\n",
            "Epoch 376/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1487 - accuracy: 0.9476 - val_loss: 0.4139 - val_accuracy: 0.7268\n",
            "Epoch 377/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0964 - accuracy: 0.9762 - val_loss: 0.1983 - val_accuracy: 0.7474\n",
            "Epoch 378/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0881 - accuracy: 0.9738 - val_loss: 0.2781 - val_accuracy: 0.7397\n",
            "Epoch 379/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0781 - accuracy: 0.9857 - val_loss: 0.2002 - val_accuracy: 0.7552\n",
            "Epoch 380/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0863 - accuracy: 0.9762 - val_loss: 0.2110 - val_accuracy: 0.7448\n",
            "Epoch 381/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0983 - accuracy: 0.9714 - val_loss: 0.1422 - val_accuracy: 0.7371\n",
            "Epoch 382/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0877 - accuracy: 0.9786 - val_loss: 0.1604 - val_accuracy: 0.7397\n",
            "Epoch 383/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0881 - accuracy: 0.9786 - val_loss: 0.2446 - val_accuracy: 0.7526\n",
            "Epoch 384/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0887 - accuracy: 0.9770 - val_loss: 0.1919 - val_accuracy: 0.7526\n",
            "Epoch 385/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0819 - accuracy: 0.9794 - val_loss: 0.2080 - val_accuracy: 0.7603\n",
            "Epoch 386/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0817 - accuracy: 0.9762 - val_loss: 0.2587 - val_accuracy: 0.7474\n",
            "Epoch 387/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0903 - accuracy: 0.9722 - val_loss: 0.2031 - val_accuracy: 0.7500\n",
            "Epoch 388/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0791 - accuracy: 0.9802 - val_loss: 0.2254 - val_accuracy: 0.7448\n",
            "Epoch 389/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0690 - accuracy: 0.9889 - val_loss: 0.1683 - val_accuracy: 0.7397\n",
            "Epoch 390/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0687 - accuracy: 0.9889 - val_loss: 0.1902 - val_accuracy: 0.7397\n",
            "Epoch 391/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0785 - accuracy: 0.9770 - val_loss: 0.1478 - val_accuracy: 0.7448\n",
            "Epoch 392/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1407 - accuracy: 0.9365 - val_loss: 0.3071 - val_accuracy: 0.7397\n",
            "Epoch 393/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2051 - accuracy: 0.9056 - val_loss: 0.7057 - val_accuracy: 0.6443\n",
            "Epoch 394/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1370 - accuracy: 0.9563 - val_loss: 0.3170 - val_accuracy: 0.6959\n",
            "Epoch 395/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1642 - accuracy: 0.9286 - val_loss: 0.4897 - val_accuracy: 0.7320\n",
            "Epoch 396/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1102 - accuracy: 0.9675 - val_loss: 0.2641 - val_accuracy: 0.7526\n",
            "Epoch 397/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0835 - accuracy: 0.9841 - val_loss: 0.2090 - val_accuracy: 0.7552\n",
            "Epoch 398/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0774 - accuracy: 0.9857 - val_loss: 0.1924 - val_accuracy: 0.7526\n",
            "Epoch 399/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0808 - accuracy: 0.9810 - val_loss: 0.2386 - val_accuracy: 0.7603\n",
            "Epoch 400/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0721 - accuracy: 0.9881 - val_loss: 0.1764 - val_accuracy: 0.7474\n",
            "Epoch 401/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0871 - accuracy: 0.9746 - val_loss: 0.2508 - val_accuracy: 0.7423\n",
            "Epoch 402/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0952 - accuracy: 0.9762 - val_loss: 0.1260 - val_accuracy: 0.7474\n",
            "Epoch 403/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1175 - accuracy: 0.9500 - val_loss: 0.1632 - val_accuracy: 0.7474\n",
            "Epoch 404/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0884 - accuracy: 0.9746 - val_loss: 0.1372 - val_accuracy: 0.7397\n",
            "Epoch 405/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0706 - accuracy: 0.9865 - val_loss: 0.2146 - val_accuracy: 0.7526\n",
            "Epoch 406/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0640 - accuracy: 0.9857 - val_loss: 0.2087 - val_accuracy: 0.7500\n",
            "Epoch 407/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0702 - accuracy: 0.9857 - val_loss: 0.1929 - val_accuracy: 0.7500\n",
            "Epoch 408/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0682 - accuracy: 0.9825 - val_loss: 0.1711 - val_accuracy: 0.7474\n",
            "Epoch 409/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0784 - accuracy: 0.9778 - val_loss: 0.2011 - val_accuracy: 0.7500\n",
            "Epoch 410/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0911 - accuracy: 0.9619 - val_loss: 0.2848 - val_accuracy: 0.7577\n",
            "Epoch 411/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1127 - accuracy: 0.9627 - val_loss: 0.4303 - val_accuracy: 0.7320\n",
            "Epoch 412/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1005 - accuracy: 0.9659 - val_loss: 0.3454 - val_accuracy: 0.7500\n",
            "Epoch 413/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0686 - accuracy: 0.9810 - val_loss: 0.2464 - val_accuracy: 0.7552\n",
            "Epoch 414/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0760 - accuracy: 0.9786 - val_loss: 0.2359 - val_accuracy: 0.7423\n",
            "Epoch 415/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0908 - accuracy: 0.9714 - val_loss: 0.1625 - val_accuracy: 0.7448\n",
            "Epoch 416/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1020 - accuracy: 0.9627 - val_loss: 0.1676 - val_accuracy: 0.7423\n",
            "Epoch 417/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0926 - accuracy: 0.9643 - val_loss: 0.1401 - val_accuracy: 0.7474\n",
            "Epoch 418/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0779 - accuracy: 0.9825 - val_loss: 0.1601 - val_accuracy: 0.7474\n",
            "Epoch 419/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0693 - accuracy: 0.9849 - val_loss: 0.2072 - val_accuracy: 0.7552\n",
            "Epoch 420/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0537 - accuracy: 0.9881 - val_loss: 0.1599 - val_accuracy: 0.7397\n",
            "Epoch 421/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0637 - accuracy: 0.9881 - val_loss: 0.2357 - val_accuracy: 0.7474\n",
            "Epoch 422/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0600 - accuracy: 0.9865 - val_loss: 0.1434 - val_accuracy: 0.7474\n",
            "Epoch 423/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0667 - accuracy: 0.9841 - val_loss: 0.1899 - val_accuracy: 0.7448\n",
            "Epoch 424/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0714 - accuracy: 0.9794 - val_loss: 0.1888 - val_accuracy: 0.7526\n",
            "Epoch 425/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0730 - accuracy: 0.9786 - val_loss: 0.1713 - val_accuracy: 0.7448\n",
            "Epoch 426/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0604 - accuracy: 0.9921 - val_loss: 0.1794 - val_accuracy: 0.7526\n",
            "Epoch 427/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0630 - accuracy: 0.9881 - val_loss: 0.2349 - val_accuracy: 0.7423\n",
            "Epoch 428/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0589 - accuracy: 0.9889 - val_loss: 0.3349 - val_accuracy: 0.7423\n",
            "Epoch 429/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0592 - accuracy: 0.9913 - val_loss: 0.2457 - val_accuracy: 0.7474\n",
            "Epoch 430/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0645 - accuracy: 0.9825 - val_loss: 0.2812 - val_accuracy: 0.7500\n",
            "Epoch 431/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0576 - accuracy: 0.9865 - val_loss: 0.1754 - val_accuracy: 0.7577\n",
            "Epoch 432/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0619 - accuracy: 0.9897 - val_loss: 0.2489 - val_accuracy: 0.7577\n",
            "Epoch 433/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0551 - accuracy: 0.9873 - val_loss: 0.2388 - val_accuracy: 0.7448\n",
            "Epoch 434/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0560 - accuracy: 0.9889 - val_loss: 0.1796 - val_accuracy: 0.7474\n",
            "Epoch 435/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0605 - accuracy: 0.9889 - val_loss: 0.2500 - val_accuracy: 0.7526\n",
            "Epoch 436/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0650 - accuracy: 0.9786 - val_loss: 0.2227 - val_accuracy: 0.7474\n",
            "Epoch 437/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0675 - accuracy: 0.9786 - val_loss: 0.2590 - val_accuracy: 0.7577\n",
            "Epoch 438/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0885 - accuracy: 0.9690 - val_loss: 0.3207 - val_accuracy: 0.7526\n",
            "Epoch 439/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1152 - accuracy: 0.9524 - val_loss: 0.3265 - val_accuracy: 0.7397\n",
            "Epoch 440/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0850 - accuracy: 0.9722 - val_loss: 0.2970 - val_accuracy: 0.7345\n",
            "Epoch 441/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0718 - accuracy: 0.9825 - val_loss: 0.3374 - val_accuracy: 0.7552\n",
            "Epoch 442/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0602 - accuracy: 0.9857 - val_loss: 0.2443 - val_accuracy: 0.7448\n",
            "Epoch 443/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0532 - accuracy: 0.9921 - val_loss: 0.1629 - val_accuracy: 0.7526\n",
            "Epoch 444/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0528 - accuracy: 0.9921 - val_loss: 0.1831 - val_accuracy: 0.7423\n",
            "Epoch 445/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0523 - accuracy: 0.9897 - val_loss: 0.2899 - val_accuracy: 0.7500\n",
            "Epoch 446/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0615 - accuracy: 0.9873 - val_loss: 0.2119 - val_accuracy: 0.7474\n",
            "Epoch 447/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.0736 - accuracy: 0.9738 - val_loss: 0.3736 - val_accuracy: 0.7474\n",
            "Epoch 448/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1440 - accuracy: 0.9317 - val_loss: 0.1734 - val_accuracy: 0.7268\n",
            "Epoch 449/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.1298 - accuracy: 0.9452 - val_loss: 0.1389 - val_accuracy: 0.6753\n",
            "Epoch 450/450\n",
            "21/21 [==============================] - 48s 2s/step - loss: 0.2064 - accuracy: 0.9143 - val_loss: 0.0893 - val_accuracy: 0.6649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "file= MatlabSpectrogram-harf/Spect_LOG_123_8910_harf+MatlabSpectrogram-kelime/Spect_LOG_123_8910_kelime, fold: f5, train score: 0.9793650507926941 test score: 0.7603092789649963 ,lr = 8e-06,\n",
            "optimizer = <class 'keras.optimizers.Adam'>, act = softmax,extralayers= [<keras.layers.core.Dropout object at 0x7feeb7a91860>],batchsize=64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brwa4D70mcxN",
        "colab_type": "text"
      },
      "source": [
        "# Testing Model and Printing Confusion Matrixes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhAwnhzLEau5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PRINT CONFUSION MATRIX \n",
        "def GetCf(model, testgens):\n",
        "    cf_sum = [[0,0],\n",
        "              [0,0]] \n",
        "    for testgen in testgens:\n",
        "      testgen.reset()\n",
        "      Y_pred = model.predict_generator(testgen,\n",
        "                                      testgen.n,verbose=1,workers=3)\n",
        "      y_pred = np.argmax(Y_pred, axis=1) \n",
        "      cf_sum = cf_sum +   confusion_matrix(testgen.classes ,y_pred) \n",
        "\n",
        "    \n",
        "    return cf_sum\n",
        "\n",
        "def PrintCf(cf_sum):   \n",
        "    target_names = ['Vigorous', 'Fatiguous']\n",
        "    sns.set(font_scale=1.6) \n",
        "    ax = sns.heatmap(cf_sum, annot = True,linewidths=.5, xticklabels=target_names,yticklabels=target_names,cmap=\"YlGnBu\",cbar=False, fmt='g')\n",
        "    plt.show()\n",
        "    \n",
        "# Test Spectrogram Model with test dataset it belongs to      \n",
        "# testAllFolds: If true, test all folds and print sum of their confusion matrixes \n",
        "# testCombined: Use model which trained with both letter and word datasets and test with both letter and word tests of current fold\n",
        "def ManualTest(sType=\"BARK\",sRange=\"12_910\",fold=\"f2\",voice=\"harf\",testAllFolds=False,testCombined=False): \n",
        "  datasets = []\n",
        "  folds = []\n",
        "  Modelvoice=voice\n",
        "  voices = [] \n",
        "\n",
        "  if (testCombined):\n",
        "    Modelvoice =\"harf+kelime\"\n",
        "    voices = [\"harf\",\"kelime\"] \n",
        "  else:\n",
        "    voices.append(voice)\n",
        "\n",
        "  if(testAllFolds):\n",
        "    folds = [\"f1\",\"f2\",\"f3\",\"f4\",\"f5\"] \n",
        "  else:\n",
        "    folds.append(fold)   \n",
        "\n",
        "  #Path of Dataset for testing\n",
        "  cf = [[0,0],[0,0]]\n",
        "  for fold in folds:\n",
        "\n",
        "    \n",
        "    #Combination prefix for Model\n",
        "    prefixModel = sType+\"_\"+sRange+\"_\"+Modelvoice+\"/\"+fold\n",
        "    \n",
        "    #prefix with extension\n",
        "    prefixWEx = prefixModel+\".h5\"\n",
        "    print(\"Testing model: \" + prefixModel + \"...\\n\")\n",
        "\n",
        "    #Path for h5\n",
        "    savedModelPath = \"Models/FVA_\"+ prefixWEx\n",
        "    #load model\n",
        "    print(\"Loading model from : \"+savedModelPath)\n",
        "    modeltmp = load_model(savedModelPath, compile=False)\n",
        "    print(\"Loaded model from : \"+savedModelPath)\n",
        "\n",
        "    datasets = []\n",
        "    for voice in voices:\n",
        "      prefixData = sType+\"_\"+sRange+\"_\"+voice+\"/\"+fold\n",
        "      datasetPath = \"MatlabSpectrogram-\"+voice+\"/\"+\"Spect_\"+prefixData\n",
        "      datasets.append(create_datagens(datasetPath,onlyTest=True)[1])\n",
        "      print(\"Testing it with test data at: \"+datasetPath)  \n",
        "    cf = cf + GetCf(modeltmp,datasets)\n",
        "\n",
        "  \n",
        "  #Get Dataset by creating test data generator and test\n",
        "  PrintCf(cf)          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGjkQXBfXw4V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "outputId": "7d193307-2f2c-4267-df75-6548f708bccb"
      },
      "source": [
        "ManualTest(sType=\"ERB\",voice=\"kelime\",testAllFolds=True,testCombined=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing model: ERB_12_910_kelime/f1...\n",
            "\n",
            "Loading model from : Models/FVA_ERB_12_910_kelime/f1.h5\n",
            "Loaded model from : Models/FVA_ERB_12_910_kelime/f1.h5\n",
            "Found 88 images belonging to 2 classes.\n",
            "Testing it with test data at: MatlabSpectrogram-kelime/Spect_ERB_12_910_kelime/f1\n",
            "88/88 [==============================] - 49s 559ms/step\n",
            "Testing model: ERB_12_910_kelime/f2...\n",
            "\n",
            "Loading model from : Models/FVA_ERB_12_910_kelime/f2.h5\n",
            "Loaded model from : Models/FVA_ERB_12_910_kelime/f2.h5\n",
            "Found 82 images belonging to 2 classes.\n",
            "Testing it with test data at: MatlabSpectrogram-kelime/Spect_ERB_12_910_kelime/f2\n",
            "82/82 [==============================] - 46s 559ms/step\n",
            "Testing model: ERB_12_910_kelime/f3...\n",
            "\n",
            "Loading model from : Models/FVA_ERB_12_910_kelime/f3.h5\n",
            "Loaded model from : Models/FVA_ERB_12_910_kelime/f3.h5\n",
            "Found 84 images belonging to 2 classes.\n",
            "Testing it with test data at: MatlabSpectrogram-kelime/Spect_ERB_12_910_kelime/f3\n",
            "84/84 [==============================] - 47s 554ms/step\n",
            "Testing model: ERB_12_910_kelime/f4...\n",
            "\n",
            "Loading model from : Models/FVA_ERB_12_910_kelime/f4.h5\n",
            "Loaded model from : Models/FVA_ERB_12_910_kelime/f4.h5\n",
            "Found 86 images belonging to 2 classes.\n",
            "Testing it with test data at: MatlabSpectrogram-kelime/Spect_ERB_12_910_kelime/f4\n",
            "86/86 [==============================] - 48s 555ms/step\n",
            "Testing model: ERB_12_910_kelime/f5...\n",
            "\n",
            "Loading model from : Models/FVA_ERB_12_910_kelime/f5.h5\n",
            "Loaded model from : Models/FVA_ERB_12_910_kelime/f5.h5\n",
            "Found 86 images belonging to 2 classes.\n",
            "Testing it with test data at: MatlabSpectrogram-kelime/Spect_ERB_12_910_kelime/f5\n",
            "86/86 [==============================] - 48s 554ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVG6cTSYpZ0l",
        "colab_type": "text"
      },
      "source": [
        "Not important, Use that if you want to change target names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKXnt1_I4gx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "7009dfa4-e957-4c1e-f04d-cd358e716fec"
      },
      "source": [
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "target_names = ['Vigorous', 'Fatiguous',]\n",
        "binary = np.array([[230, 73],\n",
        "                   [55, 400]])\n",
        "\n",
        "ax = sns.heatmap(binary, annot = True,linewidths=.5, xticklabels=target_names,yticklabels=target_names,cmap=\"YlGnBu\",cbar=False, fmt='g')\n",
        "sns.set(font_scale=1.6) \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLlQoAnz_fO-",
        "colab_type": "text"
      },
      "source": [
        "## Checking file counts for per classes on each folder to report "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjnKg30qw4ho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "221d8a41-c6b0-4619-ad2d-9597231823f4"
      },
      "source": [
        "for folder in files:\n",
        "  dinc = 0\n",
        "  yorgun = 0\n",
        "  for fold in os.listdir(folder):\n",
        "    dinc   = dinc + len(os.listdir(folder  + \"/\"+fold+ \"/Test/\" + \"dinc\"))\n",
        "    yorgun = yorgun + len(os.listdir(folder  + \"/\"+fold+ \"/Test/\" + \"yorgun\"))\n",
        "  print(folder +\", Dinc: \", dinc, \" Yorgun: \",yorgun)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MatlabSpectrogram-harf/Spect_BARK_123_8910_harf, Dinc:  438  Yorgun:  396\n",
            "MatlabSpectrogram-harf/Spect_BARK_12_910_harf, Dinc:  131  Yorgun:  197\n",
            "MatlabSpectrogram-harf/Spect_BARK_1_10_harf, Dinc:  32  Yorgun:  87\n",
            "MatlabSpectrogram-harf/Spect_ERB_123_8910_harf, Dinc:  438  Yorgun:  396\n",
            "MatlabSpectrogram-harf/Spect_ERB_12_910_harf, Dinc:  131  Yorgun:  197\n",
            "MatlabSpectrogram-harf/Spect_ERB_1_10_harf, Dinc:  32  Yorgun:  87\n",
            "MatlabSpectrogram-harf/Spect_LOG_123_8910_harf, Dinc:  438  Yorgun:  396\n",
            "MatlabSpectrogram-harf/Spect_LOG_12_910_harf, Dinc:  131  Yorgun:  197\n",
            "MatlabSpectrogram-harf/Spect_LOG_1_10_harf, Dinc:  32  Yorgun:  87\n",
            "MatlabSpectrogram-harf/Spect_MEL_123_8910_harf, Dinc:  438  Yorgun:  396\n",
            "MatlabSpectrogram-harf/Spect_MEL_12_910_harf, Dinc:  131  Yorgun:  197\n",
            "MatlabSpectrogram-harf/Spect_MEL_1_10_harf, Dinc:  32  Yorgun:  87\n",
            "MatlabSpectrogram-kelime/Spect_BARK_123_8910_kelime, Dinc:  497  Yorgun:  428\n",
            "MatlabSpectrogram-kelime/Spect_BARK_12_910_kelime, Dinc:  176  Yorgun:  254\n",
            "MatlabSpectrogram-kelime/Spect_BARK_1_10_kelime, Dinc:  40  Yorgun:  112\n",
            "MatlabSpectrogram-kelime/Spect_ERB_123_8910_kelime, Dinc:  596  Yorgun:  519\n",
            "MatlabSpectrogram-kelime/Spect_ERB_12_910_kelime, Dinc:  175  Yorgun:  251\n",
            "MatlabSpectrogram-kelime/Spect_ERB_1_10_kelime, Dinc:  23  Yorgun:  60\n",
            "MatlabSpectrogram-kelime/Spect_LOG_123_8910_kelime, Dinc:  597  Yorgun:  518\n",
            "MatlabSpectrogram-kelime/Spect_LOG_12_910_kelime, Dinc:  171  Yorgun:  253\n",
            "MatlabSpectrogram-kelime/Spect_LOG_1_10_kelime, Dinc:  41  Yorgun:  112\n",
            "MatlabSpectrogram-kelime/Spect_MEL_123_8910_kelime, Dinc:  584  Yorgun:  525\n",
            "MatlabSpectrogram-kelime/Spect_MEL_12_910_kelime, Dinc:  173  Yorgun:  261\n",
            "MatlabSpectrogram-kelime/Spect_MEL_1_10_kelime, Dinc:  43  Yorgun:  105\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}